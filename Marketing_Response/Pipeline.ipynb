{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f7b7041-b4ec-4bc7-97c0-b4f82f36fa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import font_manager\n",
    "\n",
    "# Настройки\n",
    "warnings.filterwarnings(\"ignore\", module=\"matplotlib.font_manager\")\n",
    "np.random.seed(42)\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.options.display.float_format = lambda x: ('%.12f' % x).rstrip('0').rstrip('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f222a50f-227f-4e5d-b2aa-8f19fa3fd2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_PATH = os.environ.get('PROJECT_PATH', '.')\n",
    "\n",
    "RAW_DATA_PATH = os.path.join(PROJECT_PATH, 'data/raw/MK_RAW_DATA.csv')\n",
    "PROCESSED_DATA_PATH = os.path.join(PROJECT_PATH, 'data/processed/MK_PROCESSED_DATA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052e70df-aeb6-4a7e-b8ae-718f2c49aeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Укажем путь к файлам проекта:\n",
    "# -> $PROJECT_PATH при запуске в Airflow\n",
    "# -> иначе - текущая директория при локальном запуске\n",
    "# path = os.environ.get('PROJECT_PATH', '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39dec77e-9ba5-45e2-8e14-1db47aab7c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Функция загрузки сырых данных\n",
    "def load_raw_data(path):\n",
    "    return pd.read_csv(path, sep='\\t')\n",
    "\n",
    "# Предобработка \n",
    "def preprocess(df):\n",
    "    df = df.dropna(subset=['Income'])\n",
    "    return df\n",
    "\n",
    "# Функция для удаления выбросов по IQR\n",
    "def remove_outliers_iqr(data, column):\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    filtered_data = data[(data[column] >= lower_bound) & (data[column] <= upper_bound)].copy()\n",
    "    return filtered_data\n",
    "\n",
    "# Создание признаков\n",
    "def engineer_features(df):\n",
    "    df = df.copy()\n",
    "    df['Age'] = 2025 - df['Year_Birth']\n",
    "    df['HasChildren'] = (df[['Kidhome', 'Teenhome']].sum(axis=1) > 0).astype(int)\n",
    "    df['MaritalFlag'] = df['Marital_Status'].isin(['Married', 'Together']).astype(int)\n",
    "    \n",
    "    mnt_cols = ['MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds']\n",
    "    df['TotalSpent'] = df[mnt_cols].sum(axis=1)\n",
    "    \n",
    "    df['Dt_Customer'] = pd.to_datetime(df['Dt_Customer'], dayfirst=True)\n",
    "    df['Customer_Since_Days'] = (pd.Timestamp.today() - df['Dt_Customer']).dt.days\n",
    "    df['Customer_Since_Years'] = (df['Customer_Since_Days'] / 365.25).astype(int)\n",
    "    \n",
    "    df['TotalPurchaseActivity'] = df[['NumCatalogPurchases', 'NumWebPurchases', 'NumStorePurchases', 'NumDealsPurchases']].sum(axis=1)\n",
    "    \n",
    "    df['TotalAcceptedCmp'] = df[['AcceptedCmp1', 'AcceptedCmp3', 'AcceptedCmp5', 'AcceptedCmp2', 'AcceptedCmp4']].sum(axis=1)\n",
    "    \n",
    "    higher_edu = ['Graduation', 'Master', 'PhD']\n",
    "    df['HigherEducation'] = df['Education'].isin(higher_edu).astype(int)\n",
    "    \n",
    "    # Создаем IncomeGroup для последующего признака IsHighIncome\n",
    "    df['IncomeGroup'] = pd.qcut(df['Income'], q=4, labels=['Q1', 'Q2', 'Q3', 'Q4'])\n",
    "    \n",
    "    # Создаём бинарный признак богатых покупателей\n",
    "    df['IsHighIncome'] = (df['IncomeGroup'] == 'Q4').astype(int)\n",
    "    \n",
    "    # Логарифмируем Income и TotalSpent для модели\n",
    "    df['IncomeLog'] = np.log1p(df['Income'])\n",
    "    df['TotalSpentLog'] = np.log1p(df['TotalSpent'])\n",
    "    \n",
    "    # Новый признак — откликался ли хоть на одну кампанию\n",
    "    df['AcceptedAnyCmp'] = (df['TotalAcceptedCmp'] > 0).astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Финальная очистка\n",
    "def final_cleaning_step(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Удаляем излишние столбцы\n",
    "    cols_to_drop = [\n",
    "        'ID', 'Year_Birth', 'Education', 'Marital_Status', 'Kidhome', 'Teenhome',\n",
    "        'MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts',\n",
    "        'MntGoldProds', 'NumDealsPurchases', 'NumWebPurchases', 'NumCatalogPurchases', 'NumStorePurchases',\n",
    "        'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5', 'AcceptedCmp1', 'AcceptedCmp2',\n",
    "        'Z_CostContact', 'Z_Revenue', 'Dt_Customer', 'Customer_Since_Days', 'Customer_Since_Years',\n",
    "        'Complain', 'IncomeGroup', 'TotalAcceptedCmp', 'TotalPurchaseActivity', 'Income', 'TotalSpent'\n",
    "    ]\n",
    "    \n",
    "    df.drop(columns=cols_to_drop, inplace=True, errors='ignore')\n",
    "    \n",
    "    # Удаляем дубликаты\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    \n",
    "    # Удаляем выбросы по некоторым признакам\n",
    "    for col in ['Age', 'TotalSpentLog', 'IncomeLog', 'TotalPurchaseActivity', 'NumWebVisitsMonth']:\n",
    "        if col in df.columns:\n",
    "            original_len = len(df)\n",
    "            df = remove_outliers_iqr(df, col)\n",
    "            removed = original_len - len(df)\n",
    "            print(f\"Удалено {removed} выбросов из '{col}'\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d267d48c-84a8-478b-b2a2-c28717b564ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_data_preparation_pipeline(raw_data_path):\n",
    "    raw = load_raw_data(raw_data_path)\n",
    "    clean = preprocess(raw)\n",
    "    features = engineer_features(clean)\n",
    "    final_df = final_cleaning_step(features)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4100786f-db5c-4935-b740-5e4b7223e23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_training_pipeline(df):\n",
    "    from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "    from sklearn.svm import SVC\n",
    "    from catboost import CatBoostClassifier\n",
    "\n",
    "    # Определяем признаки\n",
    "    target_column = \"Response\" \n",
    "    feature_columns = [\n",
    "        'Recency', 'NumWebVisitsMonth', 'Age', 'HasChildren',\n",
    "        'MaritalFlag', 'HigherEducation', 'IsHighIncome',\n",
    "        'AcceptedAnyCmp', 'TotalSpentLog'\n",
    "    ]\n",
    "    numeric_columns = ['Recency', 'NumWebVisitsMonth', 'Age', 'TotalSpentLog']\n",
    "\n",
    "    X = df[feature_columns]\n",
    "    y = df[target_column]\n",
    "\n",
    "    # Разделение на train/val/test\n",
    "    X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.15, stratify=y, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.1765, stratify=y_trainval, random_state=42)\n",
    "    # 0.1765 ≈ 15% из 85%, чтобы получить 70/15/15 split\n",
    "\n",
    "    # Препроцессор\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', MinMaxScaler(), numeric_columns)\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "\n",
    "    # Модели и параметры\n",
    "    models_with_params = {\n",
    "        \"CatBoost\": (\n",
    "            Pipeline([\n",
    "                ('preprocessor', preprocessor),\n",
    "                ('classifier', CatBoostClassifier(random_state=42, verbose=0, class_weights=[1, 3]))\n",
    "            ]),\n",
    "            {\n",
    "                'classifier__iterations': [50, 100],\n",
    "                'classifier__learning_rate': [0.01, 0.05],\n",
    "                'classifier__depth': [3, 4],\n",
    "                'classifier__l2_leaf_reg': [10, 20, 30]\n",
    "            }\n",
    "        ),\n",
    "        \"Ridge Classifier\": (\n",
    "            Pipeline([\n",
    "                ('preprocessor', preprocessor),\n",
    "                ('classifier', RidgeClassifier(random_state=42))\n",
    "            ]),\n",
    "            {\n",
    "                'classifier__alpha': [0.1, 1.0, 10.0],\n",
    "                'classifier__class_weight': [None, 'balanced']\n",
    "            }\n",
    "        ),\n",
    "        \"Logistic Regression\": (\n",
    "            Pipeline([\n",
    "                ('preprocessor', preprocessor),\n",
    "                ('classifier', LogisticRegression(solver=\"liblinear\", random_state=42))\n",
    "            ]),\n",
    "            {\n",
    "                'classifier__C': [0.1, 1.0, 10.0],\n",
    "                'classifier__penalty': ['l1', 'l2'],\n",
    "                'classifier__class_weight': [None, 'balanced']\n",
    "            }\n",
    "        ),\n",
    "        \"SVM - Linear Kernel\": (\n",
    "            Pipeline([\n",
    "                ('preprocessor', preprocessor),\n",
    "                ('classifier', SVC(kernel=\"linear\", probability=True, random_state=42))\n",
    "            ]),\n",
    "            {\n",
    "                'classifier__C': [0.1, 1.0, 10.0],\n",
    "                'classifier__class_weight': [None, 'balanced']\n",
    "            }\n",
    "        )\n",
    "    }\n",
    "\n",
    "    # Обучение\n",
    "    trained_models = {}\n",
    "    for name, (pipeline, params) in models_with_params.items():\n",
    "        print(f\"Обучение модели: {name}\")\n",
    "        clf = GridSearchCV(pipeline, params, cv=3, scoring='f1', verbose=0, n_jobs=-1)\n",
    "        clf.fit(X_train, y_train)\n",
    "        score = clf.score(X_val, y_val)\n",
    "        print(f\"{name} F1 на валидации: {score:.4f}\")\n",
    "        trained_models[name] = clf\n",
    "\n",
    "    return trained_models, preprocessor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (aut_ml)",
   "language": "python",
   "name": "auto_ml_venv_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
